





import pandas as pd
from sklearn.preprocessing import MinMaxScaler

# Import dataset
file_path = '/Users/lindenconrad/Desktop/USD/ADS500B/Final/house_sales.csv'  # file path
data = pd.read_csv(file_path)

# Describe dataset characteristics
print("Dataset Dimensions:", data.shape)
print("\nData Types:\n", data.dtypes)
print("\nFirst few rows of the dataset:\n", data.head())
print("\nDataset Description:\n", data.describe())

# Clean and wrangle data
# Fill missing values with the median for continuous variables
data['bedrooms'] = data['bedrooms'].fillna(data['bedrooms'].median())
data['bathrooms'] = data['bathrooms'].fillna(data['bathrooms'].median())
data['sqft_living'] = data['sqft_living'].fillna(data['sqft_living'].median())
data['sqft_lot'] = data['sqft_lot'].fillna(data['sqft_lot'].median())

# Transform data
# Convert `date` to datetime format
data['date'] = pd.to_datetime(data['date'], format='%Y%m%dT%H%M%S')

# Normalize continuous variables and create new columns for normalized values
scaler = MinMaxScaler()
data[['norm_price', 'norm_sqft_living', 'norm_sqft_lot', 'norm_sqft_above', 'norm_sqft_basement', 
      'norm_lat', 'norm_long', 'norm_sqft_living15', 'norm_sqft_lot15']] = scaler.fit_transform(
    data[['price', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'lat', 'long', 
          'sqft_living15', 'sqft_lot15']]
)

# Feature construction based on existing ones- 'age' & 'years_since_renovation'
data['age'] = 2024 - data['yr_built']
data['years_since_renovation'] = data['yr_renovated'].apply(lambda x: 2024 - x if x > 0 else 0)

# Reduce redundant data
# Drop redundant columns
data = data.drop(columns=['id', 'yr_built', 'yr_renovated'])

# Discretization: Create bins for sqft_living
data['sqft_living_bins'] = pd.cut(data['sqft_living'], bins=5, labels=False)

# Display cleaned and transformed data
print("\nCleaned and Transformed Data (first few rows):\n", data.head())

# Save the cleaned and transformed data to a new CSV file
output_file_path = '/Users/lindenconrad/Desktop/USD/ADS500B/Final/cleaned_house_sales.csv'
data.to_csv(output_file_path, index=False)
print(f"Cleaned and transformed dataset has been saved to {output_file_path}")





# Import Necessary Packages
import numpy as np
#import warnings
#warnings.simplefilter(action='ignore', category=FutureWarning)
import pandas as pd
import matplotlib as mpl
import matplotlib.pyplot as plt
plt.style.use('classic')
import seaborn as sns
import statsmodels.api as sm


# Load data into pandas object
house_sales_df = pd.read_csv('/Users/lindenconrad/Desktop/USD/ADS500B/Final/cleaned_house_sales.csv',header=0, sep=',')
house_sales_df.head()


# Creating a histogram of House Price
plt.hist(house_sales_df['price'], bins=50, alpha=0.5,
         histtype='stepfilled', color='steelblue',
         edgecolor='none')
plt.xlabel('House Price (USD)')
plt.ylabel('Frequency')
plt.title('Distribution of House Price');


#Box plot of house price by number of floors
sns.boxplot(x="floors", y="price", data=house_sales_df)


#Box plot of square feet of living space by bathrooms
sns.boxplot(x="bathrooms", y="sqft_living", data=house_sales_df)
plt.xticks(fontsize=8)
plt.show()


plt.scatter(house_sales_df.loc[:,['age']], house_sales_df.loc[:,['sqft_living']], marker='o')
plt.xlabel('Age')
plt.ylabel('SQFT of Living Space')
plt.title('Average vs Size of Living Space')


# Correlation Matrix for Quantitative Data
house_sales_quant = house_sales_df.select_dtypes((int, float))
correlations = house_sales_quant.corr()
print(correlations)




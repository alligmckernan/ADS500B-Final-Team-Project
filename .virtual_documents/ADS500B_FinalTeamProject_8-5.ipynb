





import pandas as pd
from sklearn.preprocessing import MinMaxScaler

# Import dataset
file_path = '/Users/lindenconrad/Desktop/USD/ADS500B/Final/house_sales.csv'  # file path
data = pd.read_csv(file_path)

# Describe dataset characteristics
print("Dataset Dimensions:", data.shape)
print("\nData Types:\n", data.dtypes)
print("\nFirst few rows of the dataset:\n", data.head())
print("\nDataset Description:\n", data.describe())

# Clean and wrangle data
# Fill missing values with the median for continuous variables
data['bedrooms'] = data['bedrooms'].fillna(data['bedrooms'].median())
data['bathrooms'] = data['bathrooms'].fillna(data['bathrooms'].median())
data['sqft_living'] = data['sqft_living'].fillna(data['sqft_living'].median())
data['sqft_lot'] = data['sqft_lot'].fillna(data['sqft_lot'].median())

# Transform data
# Convert `date` to datetime format
data['date'] = pd.to_datetime(data['date'], format='%Y%m%dT%H%M%S')

# Normalize continuous variables and create new columns for normalized values
scaler = MinMaxScaler()
data[['norm_price', 'norm_sqft_living', 'norm_sqft_lot', 'norm_sqft_above', 'norm_sqft_basement', 
      'norm_lat', 'norm_long', 'norm_sqft_living15', 'norm_sqft_lot15']] = scaler.fit_transform(
    data[['price', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'lat', 'long', 
          'sqft_living15', 'sqft_lot15']]
)

# Feature construction based on existing ones- 'age' & 'years_since_renovation'
data['age'] = 2024 - data['yr_built']
data['years_since_renovation'] = data['yr_renovated'].apply(lambda x: 2024 - x if x > 0 else 0)

# Reduce redundant data
# Drop redundant columns
data = data.drop(columns=['id', 'yr_built', 'yr_renovated'])

# Discretization: Create bins for sqft_living
data['sqft_living_bins'] = pd.cut(data['sqft_living'], bins=5, labels=False)

# Display cleaned and transformed data
print("\nCleaned and Transformed Data (first few rows):\n", data.head())

# Save the cleaned and transformed data to a new CSV file
output_file_path = '/Users/lindenconrad/Desktop/USD/ADS500B/Final/cleaned_house_sales.csv'
data.to_csv(output_file_path, index=False)
print(f"Cleaned and transformed dataset has been saved to {output_file_path}")





# Import Necessary Packages
import numpy as np
#import warnings
#warnings.simplefilter(action='ignore', category=FutureWarning)
import pandas as pd
import matplotlib as mpl
import matplotlib.pyplot as plt
plt.style.use('classic')
import seaborn as sns
import statsmodels.api as sm


# Load data into pandas object
house_sales_df = pd.read_csv('/Users/lindenconrad/Desktop/USD/ADS500B/Final/cleaned_house_sales.csv',header=0, sep=',')
house_sales_df.head()


# Creating a histogram of House Price
plt.hist(house_sales_df['price'], bins=50, alpha=0.5,
         histtype='stepfilled', color='steelblue',
         edgecolor='none')
plt.xlabel('House Price (USD)')
plt.ylabel('Frequency')
plt.title('Distribution of House Price');


#Box plot of house price by number of floors
sns.boxplot(x="floors", y="price", data=house_sales_df)


#Box plot of square feet of living space by bathrooms
sns.boxplot(x="bathrooms", y="sqft_living", data=house_sales_df)
plt.xticks(fontsize=8)
plt.show()


plt.scatter(house_sales_df.loc[:,['age']], house_sales_df.loc[:,['sqft_living']], marker='o')
plt.xlabel('Age')
plt.ylabel('SQFT of Living Space')
plt.title('Average vs Size of Living Space')


# Correlation Matrix for Quantitative Data
house_sales_quant = house_sales_df.select_dtypes((int, float))
correlations = house_sales_quant.corr()
print(correlations)








# Imports
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Load the cleaned dataset
cleaned_df = pd.read_csv('cleaned_house_sales.csv')

# Display the first few rows of the dataset
print(cleaned_df.head())





# Using both Square footage and price as our variables
X = cleaned_df[['sqft_living']]
y = cleaned_df['price']


# Split the data into training and testing sets at 80%
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# Initialize the model
model = LinearRegression()

# Train the model
model.fit(X_train, y_train)


# Make predictions on the test set
y_pred = model.predict(X_test)

# Calculate evaluation metrics
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")





X = cleaned_df[['bathrooms']]
y = cleaned_df['price']


# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# Initialize the model
model = LinearRegression()

# Train the model
model.fit(X_train, y_train)


# Make predictions on the test set
y_pred = model.predict(X_test)

# Calculate evaluation metrics
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")






